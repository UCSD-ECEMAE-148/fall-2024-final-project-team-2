"use strict";(self.webpackChunkUCSD_ECEMAE_148=self.webpackChunkUCSD_ECEMAE_148||[]).push([[480],{5991:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var n=t(4848),a=t(8453);const s={id:"roboflow",title:"Roboflow with OAKD-Lite",tags:["Roboflow","Oakd-Lite","DepthAI","OpenCV2"],sidebar_position:6,last_update:{date:"12/14/2024",author:"Brian Sun"}},i="Roboflow with OAKD-Lite",r={id:"roboflow/roboflow",title:"Roboflow with OAKD-Lite",description:"We used our class docker image to develop our initial Roboflow code.",source:"@site/docs/roboflow/index.mdx",sourceDirName:"roboflow",slug:"/roboflow/",permalink:"/fall-2024-final-project-team-2/docs/roboflow/",draft:!1,unlisted:!1,tags:[{label:"Roboflow",permalink:"/fall-2024-final-project-team-2/docs/tags/roboflow"},{label:"Oakd-Lite",permalink:"/fall-2024-final-project-team-2/docs/tags/oakd-lite"},{label:"DepthAI",permalink:"/fall-2024-final-project-team-2/docs/tags/depth-ai"},{label:"OpenCV2",permalink:"/fall-2024-final-project-team-2/docs/tags/open-cv-2"}],version:"current",lastUpdatedBy:"Brian Sun",lastUpdatedAt:1734163200,formattedLastUpdatedAt:"Dec 14, 2024",sidebarPosition:6,frontMatter:{id:"roboflow",title:"Roboflow with OAKD-Lite",tags:["Roboflow","Oakd-Lite","DepthAI","OpenCV2"],sidebar_position:6,last_update:{date:"12/14/2024",author:"Brian Sun"}},sidebar:"noteSidebar",previous:{title:"Lane Tracking with ROS2 and OpenCV2",permalink:"/fall-2024-final-project-team-2/docs/lane-tracking/"},next:{title:"Retrieval-augmented Memory for Embodied Robots",permalink:"/fall-2024-final-project-team-2/docs/remember/"}},l={},c=[];function d(e){const o={code:"code",h1:"h1",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(o.h1,{id:"roboflow-with-oakd-lite",children:"Roboflow with OAKD-Lite"}),"\n",(0,n.jsx)(o.p,{children:"We used our class docker image to develop our initial Roboflow code."}),"\n",(0,n.jsx)(o.p,{children:"Within our docker container, we have to ensure the X11 forwarding is set up. Once set up, we can proceed to give permissions to the OAKD-lite camera.\r\nThis can be done by running these commands within both Jetson Nano and inside our docker container."}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-bash",children:'export OPENBLAS_CORETYPE=ARMV8" >> ~/.bashrc\r\necho \'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"\' | sudo tee /etc/udev/rules.d/80-movidius.rules\n'})}),"\n",(0,n.jsx)(o.p,{children:"We can then install depthai with the following commands below."}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-bash",children:"RUN git clone https://github.com/luxonis/depthai.git && \\\r\n    git clone https://github.com/luxonis/depthai-python.git && \\\r\n    cd depthai && \\\r\n    source ${VIRTUAL_ENV}/donkey/bin/activate && \\\r\n    curl -fL https://docs.luxonis.com/install_dependencies.sh | bash && \\\r\n    python3 install_requirements.py && \\\r\n    cd ../depthai-python/examples && \\\r\n    python3 install_requirements.py \n"})}),"\n",(0,n.jsxs)(o.p,{children:["Once done, we can simply run the test model within ",(0,n.jsx)(o.code,{children:"/depthai-python/examples"}),":"]}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-bash",children:"python3 human_pose.py\n"})}),"\n",(0,n.jsx)(o.p,{children:"The source code is only 6 lines of code."}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"from depthai_sdk import OakCamera\r\n\r\nwith OakCamera() as oak:\r\n  color = oak.create_camera('color')\r\n  # List of models that are supported out-of-the-box by the SDK:\r\n  # https://docs.luxonis.com/projects/sdk/en/latest/features/ai_models/#sdk-supported-models\r\n  human_pose_nn = oak.create_nn('human-pose-estimation-0001', color)\r\n\r\n  oak.visualize(human_pose_nn)\r\n  oak.start(blocking=True)\n"})}),"\n",(0,n.jsx)(o.p,{children:"We can then get this demo."}),"\n",(0,n.jsx)("div",{style:{display:"flex",justifyContent:"center",alignItems:"center"},children:(0,n.jsx)("img",{src:"https://docs-old.luxonis.com/projects/sdk/en/latest/_images/sdk_human_pose.gif",alt:"Raccoon Dancing"})})]})}function p(e={}){const{wrapper:o}={...(0,a.R)(),...e.components};return o?(0,n.jsx)(o,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,o,t)=>{t.d(o,{R:()=>i,x:()=>r});var n=t(6540);const a={},s=n.createContext(a);function i(e){const o=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function r(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),n.createElement(s.Provider,{value:o},e.children)}}}]);